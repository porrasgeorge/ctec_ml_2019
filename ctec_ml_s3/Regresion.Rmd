---
title: "Regresion"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tarea 3.
# Regresión lineal

# Jorge Porras Araya


Análisis del Problema

El desempeño de un automóvil se puede medir de diferentes formas. Algunas comunes son la cantidad de caballos de fuerza y el rendimiento del mismo, que se puede resumir en cuantas millas puede recorrer el automóvil por cada galón de combustible que consume. Para los clientes, potenciales compradores de un automóvil, este rendimiento es importante pues puede ayudar a tomar una decisión con respecto a cuál automóvil comprar (si, por ejemplo, el cliente quiere un auto que rinda por muchas millas y pueda economizar en la compra de combustible).

Desde este punto de vista, tanto a clientes como a fabricadores de automóviles, les conviene entender cuál es la relación entre diferentes características del automóvil y su rendimiento, pues el conocer estas relaciones les puede ayudar a inferir cuál va a ser la eficiencia del vehículo a partir de ver los valores de otras características. Para fabricantes, puede ser importante conocer estas relaciones para saber cómo hacer cada modelo más eficiente con respecto al anterior.

Entendimiento de los Datos

Con el fin de analizar y tratar de estimar las millas por galón de diferentes modelos de automóviles, se trabajó con un conjunto de datos que contiene 398 observaciones y 9 variables:

- mpg (millas por galón): numérica, con un rango de 9 a 46.60.
- cyl (cilindraje): categórica ordinal, con valores posibles de 3, 4, 5, 6 y 8.
- disp (desplazamiento): numérica, con un rango de 68 a 455.
- hp (caballos de fuerza): numérica, con un rango de 46 a 230 y 6 valores faltantes.
- weight (peso): numérica, con un rango de 1613 a 5140.
- acc (aceleración): numérica, con un rango de 8 a 24.80.
- model year (año): categórica, con 13 valores diferentes representando el año del automóvil.
- origin (origen): categórica, 3 valores posibles: 1, 2, 3.
- model name (nombre del modelo): categórica, con 305 posibles valores.

# Ejercicios 

## Prueba 1


1. Cargue el archivo auto-mpg_g.csv en una variable
```{r}
  library(GGally)
  library(MASS)
  library(caTools)
  library(visdat)
  library(Metrics)
  library(dplyr)
```

Se lee el archivo .csv
La visualizacion de los datos nos muestra que no tenemos valores nulos
model.name es un factor
Se eliminan las variables categoricas
Se eliminan las filas con hp = 0, pues si se desea emplear escala logaritmica, log(0) esta indefinido (-inf), ademas no pueden existir vehiculos con potencia = 0hp

```{r}
  autosCSV <- read.csv("auto-mpg_g.csv")
  autos <- autosCSV %>% 
    select (mpg, disp, hp, weight, acc, cyl, model.name) %>% 
    filter(hp > 0)

  vis_dat(autos)
```


```{r}
boxplot(autos$mpg, 
        main="Consumo de combustible",
        ylab="mpg")

boxplot(autos$hp, 
        main="Potencia",
        ylab="hp")

boxplot(autos$weight, 
        main="Peso",
        ylab="pounds")

```


de los histogramas se puede observar que existen algunos puntos en hp que son considerados outliers, sin embargo se decide no eliminarlos pues son valores reales de potencia de vehiculos (valores mayores a 200 hp).

```{r}
  outliers <- boxplot(autos$hp, plot = F)$out
  outliers
```



2. Utilizando Ggpairs cree un gráfico de los atributos del dataset, observe las correlaciones entre atributos

```{r}
  ggpairs(autos[-7], progress = F)
```

3. Separe los datos en 2 conjuntos, uno de entrenamiento y otro de pruebas. Normalmente se trabaja utilizando un 70-80% de los datos para entrenamiento y el resto para pruebas.

Recuerde fijar una semilla para que el documento sea reproducible.

Pista: https://www.rdocumentation.org/packages/caTools/versions/1.17.1/topics/sample.split
```{r}
  set.seed(4)
  mask <- sample.split(autos$model.name, 
                       SplitRatio = 7/10)

  training_data <- autos[mask, c(1, 2, 3, 4, 5, 6)]
  test_data <- autos[!mask, c(1, 2, 3, 4, 5, 6)]

```

revisando la relacion entre los datos de entrenamiento y los de prueba se puede observar que la relacion es de aproximadamente 70%, el cual es el valor esperado.
```{r}
  ratio <- 100 * length(training_data$mpg) /
    (length(training_data$mpg) + length(test_data$mpg))
  
ratio

```


utilizando como variable objetivo mpg y como variables predictoras hp, disp y weight, se realiza un histograma para observar el comportamiento de las variables, pero sin embargo regresion lineal no requiere de una distribucion normal de los datos.

```{r}
hist(training_data$mpg)
hist(training_data$hp)
hist(training_data$weight)
hist(training_data$disp)

```


luego se crean hitogramas de las mismas variables pero esta vez en escala logaritmica, donde se observa que para ninguno de los casos se llega a una distribucion normal. 

```{r}
hist(log(training_data$mpg))
hist(log(training_data$hp))
hist(log(training_data$weight))
hist(log(training_data$disp))

```

Se realiza un plot de cada una de las variables contra la variable mpg, donde se puede observar que se tienen distribuciones relativamente lineales (mas adelante se probaran algunas modificaciones). 


```{r}
  plot(training_data$hp, training_data$mpg)
```



```{r}
  plot(training_data$weight, training_data$mpg)
```


```{r}
  plot(training_data$disp, training_data$mpg)
```



4. Cree un modelo de regresion lineal utilizando el atributo mpg como la variable objetivo y en base a las correlaciones observadas en el gráfico del punto 2 escoja al menos dos atributos para usarlos como variables predictoras para el modelo.

Nota: Al crear el modelo utilice el conjunto de datos de entrenamiento definido en el punto 3.


```{r}

  line_model <- lm(mpg ~ hp + weight, data = training_data)
  print(line_model)

```


5. Realice predicciones utilizando el conjunto de pruebas y evalue el resultado con la métrica MSE.

  Se puede observar que para los datos de prueba, en la mayoria de los casos las predicciones se aproximan al valor real, idealmente deberian estar lo mas cercano posible a la recta con pendiente unitaria y interseccion con "y" en cero (recta en color morado). 

```{r}
  predicted_data  <- predict(line_model, test_data)
  predicts_real <- data.frame(cbind(real_value=test_data$mpg, predicted_value = predicted_data, difference = abs(test_data$mpg- predicted_data)))
  plot(predicts_real$real_value, predicts_real$predicted_value, xlim = c(10, 45), ylim = c(10, 45))
  abline(a = 0, b = 1, col = "purple", lwd = 4)
  
```


La metrica MSE da un valor de 17.56 para este modelo.

```{r}
mse(predicts_real$predicted,predicts_real$real)

```



6. Opcional

6.a Pruebe varios modelos que utilicen diferentes variables y comparar los resultados obtenidos

6.b Investigar como implementar en R las técnicas de preprocesado y normalización vistas en clase y aplicarlas a los datos antes de pasarlos al modelo.


Utilizando logaritmos en las distintas variables para tratar de generar una distribucion con mayor semejanza a la curva normal, se obserba como para las variables "hp", "weight" y "disp" se obtiene una distribucion un pococo mas lineal cuando se grafican contra el logaritmo de "mpg" en vez de contra "mpg" 


```{r}
  
  plot(training_data$hp, training_data$mpg)
  plot(training_data$hp, log(training_data$mpg))
  plot(log(training_data$hp), log(training_data$mpg))
  

```



```{r}
  
  plot(training_data$weight, training_data$mpg)
  plot(training_data$weight, log(training_data$mpg))
  plot(log(training_data$weight), log(training_data$mpg))
  

```


```{r}
  
  plot(training_data$disp, training_data$mpg)
  plot(training_data$disp, log(training_data$mpg))
  plot(log(training_data$disp), log(training_data$mpg))
  

```

  se crea el modelo de regresion con la variable log(mpg).


```{r}
line_model <- lm(log(mpg) ~ hp + weight, data = training_data)
```


Se grafican los datos que se predijeron contra los datos reales, de igual manera se nota una dispersion semejante a la del metodo anterior.


```{r}
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = exp(predicted_data)))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
```



Sin embargo la métrica MSE arroja un resultado ligeramente mejor.

```{r}
mse(predicts_real$predicted,predicts_real$real)
```

Utilizando diversas variables y distintos procesados a las mismas, se obtienen metricas muy semejantes, como se puede observar a continuacion, en donde aunque se traten las variable con funciones logaritmicas (ni con el inverso multiplicativo como en el ultimo ejemplo), los resultados no varian de forma significativa.



```{r}
line_model <- lm(mpg ~ hp + weight + disp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)
```


```{r}
line_model <- lm(mpg ~ hp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)
```


```{r}
line_model <- lm(mpg ~ weight, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```


```{r}
line_model <- lm(mpg ~ weight + disp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```




```{r}
line_model <- lm(mpg ~ log(hp), data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```


```{r}
line_model <- lm(mpg ~ log(weight), data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```


```{r}
line_model <- lm(mpg ~ log(weight) + disp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```



```{r}
line_model <- lm(mpg ~ log(weight) + log(disp), data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = predicted_data))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```



```{r}
line_model <- lm(log(mpg) ~ log(weight) + log(disp), data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = exp(predicted_data)))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```

```{r}
line_model <- lm(log(mpg) ~ disp + weight + hp + acc, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = exp(predicted_data)))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```



```{r}
line_model <- lm(log(mpg) ~ log(disp) + weight + hp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = exp(predicted_data)))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```


```{r}
line_model <- lm(1/(mpg) ~ disp + weight + hp, data = training_data)
predicted_data  <- predict(line_model, test_data)
predicts_real <- data.frame(cbind(real=test_data$mpg, predicted = 1/(predicted_data)))
plot(predicts_real, xlim = c(10, 45), ylim = c(10, 45))
abline(a = 0, b = 1, col = "purple", , lwd = 4)
mse(predicts_real$predicted,predicts_real$real)

```

